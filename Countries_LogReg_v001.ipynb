{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8fa3dfd-2fd1-425a-b850-6264639551a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/ML/\n",
      "Afganistan\n",
      "China\n",
      "CAR\n",
      "Ethiopia\n",
      "India\n",
      "Iran\n",
      "KNDR\n",
      "Libya\n",
      "Morocco\n",
      "Sudan\n",
      "Syria\n",
      "Turkey\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "DOWNLOAD_ROOT = \"D:/ML/\"\n",
    "print(DOWNLOAD_ROOT)\n",
    "DATASET_PATH = os.path.join(\"datasets\", \"Countries\")\n",
    "DIR_PATH = {\"Afganistan\":os.path.join(DATASET_PATH, \"Afganistan\"),\n",
    "            \"China\":os.path.join(DATASET_PATH, \"China\"),\n",
    "            \"CAR\":os.path.join(DATASET_PATH, \"CAR\"),\n",
    "           \"Ethiopia\":os.path.join(DATASET_PATH, \"Ethiopia\"),\n",
    "           \"India\":os.path.join(DATASET_PATH, \"India\"),\n",
    "           \"Iran\":os.path.join(DATASET_PATH, \"Iran\"),\n",
    "            \"KNDR\":os.path.join(DATASET_PATH, \"KNDR\"),\n",
    "            \"Libya\":os.path.join(DATASET_PATH, \"Libya\"),\n",
    "           \"Morocco\":os.path.join(DATASET_PATH, \"Morocco\"),\n",
    "           \"Sudan\":os.path.join(DATASET_PATH, \"Sudan\"),\n",
    "           \"Syria\":os.path.join(DATASET_PATH, \"Syria\"),\n",
    "           \"Turkey\":os.path.join(DATASET_PATH, \"Turkey\"),\n",
    "           }\n",
    "filenames = {}\n",
    "for items in DIR_PATH.keys():\n",
    "    print(items)\n",
    "    filenames[items] = [name for name in sorted(os.listdir(DIR_PATH[items])) if len(name) > 20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1df2bc88-3e04-4d01-ba1c-44d4dc6e40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from charset_normalizer import from_path\n",
    "import string\n",
    "\n",
    "def remove_chars_from_text(text, chars):\n",
    "    # return \"\".join([ch for ch in text if ch not in chars])\n",
    "    content = ''\n",
    "    for ch in text:\n",
    "        if ch not in chars:\n",
    "            content = content + ''.join(ch)\n",
    "        else:\n",
    "            content = content + ''.join(' ')\n",
    "    return content\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "spec_chars = string.punctuation + '\\r' + '\\n\\xa0«»\\t—…' \n",
    "\n",
    "x_temp = []\n",
    "y_temp = []\n",
    "for item in filenames.keys():\n",
    "    post_temp=[]\n",
    "    for names in filenames[item]:\n",
    "        content = str(from_path(DIR_PATH[item]+\"\\\\\"+names).best()).lower()  \n",
    "        content = remove_emojis(content)\n",
    "        # content = re.sub(r'(\\\\u[0-9A-Fa-f]+)', lambda matchobj: chr(int(matchobj.group(0)[2:], 16)), content)\n",
    "        content = remove_chars_from_text(content, spec_chars)\n",
    "        content = remove_chars_from_text(content, string.digits)\n",
    "        for i in range(1, 10):\n",
    "            content = content.replace('  ', ' ')\n",
    "        x_temp.append(content)\n",
    "        y_temp.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc99313d-74a1-4012-a600-1fd50b222455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = np.array(x_temp, dtype=object)\n",
    "y = np.array(y_temp)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1eb4c12-2fc7-49f0-bf65-7e46c8b52715",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import urlextract # may require an Internet connection to download root domain names\n",
    "    \n",
    "    url_extractor = urlextract.URLExtract()\n",
    "except ImportError:\n",
    "    url_extractor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e104920-1308-4f62-9cbb-c0cc53c13565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import urlextract # may require an Internet connection to download root domain names\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from tokenizer_exceptions import normalizer_exc_rus\n",
    "ru_stopwords = set(\n",
    "        \"\"\"\n",
    "    а авось ага агу аж ай али алло ау ах ая\n",
    "    б будем будет будете будешь буду будут будучи будь будьте бы был была были было\n",
    "    быть бац без безусловно бишь благо благодаря ближайшие близко более больше\n",
    "    будто бывает бывала бывали бываю бывают бытует\n",
    "    в вам вами вас весь во вот все всё всего всей всем всём всеми всему всех всею\n",
    "    всея всю вся вы ваш ваша ваше ваши вдали вдобавок вдруг ведь везде вернее\n",
    "    взаимно взаправду видно вишь включая вместо внакладе вначале вне вниз внизу\n",
    "    вновь вовсе возможно воистину вокруг вон вообще вопреки вперекор вплоть\n",
    "    вполне вправду вправе впрочем впрямь вресноту вроде вряд всегда всюду\n",
    "    всякий всякого всякой всячески вчеред\n",
    "    г го где гораздо гав\n",
    "    д да для до дабы давайте давно давным даже далее далеко дальше данная\n",
    "    данного данное данной данном данному данные данный данных дану данунах\n",
    "    даром де действительно довольно доколе доколь долго должен должна\n",
    "    должно должны должный дополнительно другая другие другим другими\n",
    "    других другое другой\n",
    "    е его едим едят ее её ей ел ела ем ему емъ если ест есть ешь еще ещё ею едва\n",
    "    ежели еле\n",
    "    ж же\n",
    "    з за затем зато зачем здесь значит зря\n",
    "    и из или им ими имъ их ибо иль имеет имел имела имело именно иметь иначе\n",
    "    иногда иным иными итак ишь\n",
    "    й\n",
    "    к как кем ко когда кого ком кому комья которая которого которое которой котором\n",
    "    которому которою которую которые который которым которыми которых кто ка кабы\n",
    "    каждая каждое каждые каждый кажется казалась казались казалось казался казаться\n",
    "    какая какие каким какими каков какого какой какому какою касательно кой коли\n",
    "    коль конечно короче кроме кстати ку куда\n",
    "    л ли либо лишь любая любого любое любой любом любую любыми любых\n",
    "    м меня мне мной мною мог моги могите могла могли могло могу могут мое моё моего\n",
    "    моей моем моём моему моею можем может можете можешь мои мой моим моими моих\n",
    "    мочь мою моя мы мало меж между менее меньше мимо многие много многого многое\n",
    "    многом многому можно мол му\n",
    "    н на нам нами нас наса наш наша наше нашего нашей нашем нашему нашею наши нашим\n",
    "    нашими наших нашу не него нее неё ней нем нём нему нет нею ним ними них но\n",
    "    наверняка наверху навряд навыворот над надо назад наиболее наизворот\n",
    "    наизнанку наипаче накануне наконец наоборот наперед наперекор наподобие\n",
    "    например напротив напрямую насилу настоящая настоящее настоящие настоящий\n",
    "    насчет нате находиться начала начале неважно негде недавно недалеко незачем\n",
    "    некем некогда некому некоторая некоторые некоторый некоторых некто некуда\n",
    "    нельзя немногие немногим немного необходимо необходимости необходимые\n",
    "    необходимым неоткуда непрерывно нередко несколько нету неужели нечего\n",
    "    нечем нечему нечто нешто нибудь нигде ниже низко никак никакой никем\n",
    "    никогда никого никому никто никуда ниоткуда нипочем ничего ничем ничему\n",
    "    ничто ну нужная нужно нужного нужные нужный нужных ныне нынешнее нынешней\n",
    "    нынешних нынче\n",
    "    о об один одна одни одним одними одних одно одного одной одном одному одною\n",
    "    одну он она оне они оно от оба общую обычно ого однажды однако ой около оный\n",
    "    оп опять особенно особо особую особые откуда отнелижа отнелиже отовсюду\n",
    "    отсюда оттого оттот оттуда отчего отчему ох очевидно очень ом\n",
    "    п по при паче перед под подавно поди подобная подобно подобного подобные\n",
    "    подобный подобным подобных поелику пожалуй пожалуйста позже поистине\n",
    "    пока покамест поколе поколь покуда покудова помимо понеже поприще пор\n",
    "    пора посему поскольку после посреди посредством потом потому потомушта\n",
    "    похожем почему почти поэтому прежде притом причем про просто прочего\n",
    "    прочее прочему прочими проще прям пусть\n",
    "    р ради разве ранее рано раньше рядом\n",
    "    с сам сама сами самим самими самих само самого самом самому саму свое своё\n",
    "    своего своей своем своём своему своею свои свой своим своими своих свою своя\n",
    "    себе себя собой собою самая самое самой самый самых сверх свыше се сего сей\n",
    "    сейчас сие сих сквозь сколько скорее скоро следует слишком смогут сможет\n",
    "    сначала снова со собственно совсем сперва спокону спустя сразу среди сродни\n",
    "    стал стала стали стало стать суть сызнова\n",
    "    та то ту ты ти так такая такие таким такими таких такого такое такой таком такому такою\n",
    "    такую те тебе тебя тем теми тех тобой тобою того той только том томах тому\n",
    "    тот тою также таки таков такова там твои твоим твоих твой твоя твоё\n",
    "    теперь тогда тоже тотчас точно туда тут тьфу тая\n",
    "    у уже увы уж ура ух ую\n",
    "    ф фу\n",
    "    х ха хе хорошо хотел хотела хотелось хотеть хоть хотя хочешь хочу хуже\n",
    "    ч чего чем чём чему что чтобы часто чаще чей через чтоб чуть чхать чьим\n",
    "    чьих чьё чё\n",
    "    ш ша\n",
    "    щ ща щас\n",
    "    ы ых ые ый\n",
    "    э эта эти этим этими этих это этого этой этом этому этот этою эту эдак эдакий\n",
    "    эй эка экий этак этакий эх\n",
    "    ю\n",
    "    я явно явных яко якобы якоже\n",
    "    \n",
    "    и что не это  быть этот это свой как - этот весь быть что ▫ но г. %\n",
    "    \"\"\".split()\n",
    "    )\n",
    "# stemmer = nltk.PorterStemmer()\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "def Make_dict(X_text, strip_headers=True, lower_case=True,\n",
    "    remove_punctuation=True, replace_urls=True, replace_numbers=True,\n",
    "    stemming=True, remove_stopwords=True):\n",
    "    \n",
    "    X_transformed = []\n",
    "    for email in X_text:\n",
    "        text = email or \"\"\n",
    "        text = normalizer_exc_rus(text)\n",
    "        if lower_case:\n",
    "            text = text.lower()\n",
    "        if replace_urls and url_extractor is not None:\n",
    "            urls = list(set(url_extractor.find_urls(text)))\n",
    "            urls.sort(key=lambda url: len(url), reverse=True)\n",
    "            for url in urls:\n",
    "                text = text.replace(url, \"\")\n",
    "        if replace_numbers:\n",
    "            text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', '', text)\n",
    "        if remove_punctuation:\n",
    "            text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "        if remove_stopwords:\n",
    "            filtered_words = []\n",
    "            for token in text.split():\n",
    "                if token not in ru_stopwords and len(token)>2:\n",
    "                    filtered_words.append(token)\n",
    "    \n",
    "            # Join the filtered words to form a clean text\n",
    "            text = ' '.join(filtered_words)\n",
    "        word_counts = Counter(text.split())\n",
    "        if stemming and stemmer is not None:\n",
    "            stemmed_word_counts = Counter()\n",
    "            for word, count in word_counts.items():\n",
    "                stemmed_word = stemmer.stem(word)\n",
    "                stemmed_word_counts[stemmed_word] += count\n",
    "            word_counts = stemmed_word_counts\n",
    "        X_transformed.append(word_counts)\n",
    "    return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "278c7b06-d0bb-4227-84aa-2fc590a9d407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['распп', 'приглашает', 'предпринимателей', 'сферы', 'креативных', 'индустрий', 'принять']\n"
     ]
    }
   ],
   "source": [
    "X_train_dic = Make_dict(X_train, stemming=False)\n",
    "X_train_words = []\n",
    "for post in X_train_dic:\n",
    "    for word in post.keys():\n",
    "        X_train_words.append(word)\n",
    "print(X_train_words [:7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d0bc31c-0530-4b5c-ba4f-88c390a3cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(vocabulary = set(X_train_words))\n",
    "X_train_transformed = count.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38786cc6-81bb-491a-a6d5-bb8960724c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ae10f83-4000-4430-868d-cfcf6b11c999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4195, 64099)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb474969-428d-40e2-a0a2-06c10484f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.894) total time=   1.8s\n",
      "[CV] END ................................ score: (test=0.896) total time=   1.7s\n",
      "[CV] END ................................ score: (test=0.888) total time=   1.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8927290867548624"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=5000, random_state=42, n_jobs=-1)\n",
    "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66d33059-e159-487c-b23f-12a2709a502b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aaa', 'aamiddleeast', 'aap', ..., 'ፖሊስ', 'ፖሊቴክኒክ', '፲፪ቱ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24febdb5-06cd-4fb6-bcb5-6a8eeefb20a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 99.43%\n",
      "Recall: 99.43%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_test_transformed = count.transform(X_test)\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=6000, random_state=42)\n",
    "log_clf.fit(X_test_transformed, y_test)\n",
    "\n",
    "y_pred = log_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred, average='micro')))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d4bdba38-2351-4a27-a35f-e793be566efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('contry_post-model.bin', 'wb') as f_out:\n",
    "    pickle.dump([log_clf, X_train_words], f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05cb53a2-d829-49c1-bb8e-34cb8971ef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CAR' 'Afganistan' 'China' 'India' 'China']\n",
      "Predicted Probabilities: ['CAR' 'Afganistan' 'China' 'India' 'China'] - [[0.0448222  0.36177531 0.11550723 0.04667658 0.11084489 0.08282343\n",
      "  0.0305585  0.02454119 0.04100519 0.05247193 0.02360906 0.06536449]\n",
      " [0.44815044 0.06460173 0.14934964 0.05469975 0.11821455 0.06541259\n",
      "  0.0077006  0.01619594 0.01583552 0.02617368 0.00706328 0.02660227]\n",
      " [0.01251511 0.03820323 0.74257934 0.01038435 0.13160822 0.02950085\n",
      "  0.00261869 0.00527948 0.0049725  0.0089878  0.0051484  0.00820203]\n",
      " [0.03275996 0.06204704 0.0857326  0.06225232 0.49906975 0.14011849\n",
      "  0.00654088 0.01455936 0.02650484 0.03389317 0.00807525 0.02844632]\n",
      " [0.03130359 0.12612958 0.4384318  0.02873554 0.16295036 0.10619044\n",
      "  0.00893254 0.01639647 0.01606741 0.01604553 0.00837593 0.0404408 ]]\n"
     ]
    }
   ],
   "source": [
    "new_text = ['Нигер последовал примеру Мали, разорвав связи с Украиной после того, как пресс-секретарь разведывательного агентства Министерства обороны Украины признал, что Украина оказывала поддержку повстанцам, которые убили малийских вооруженных сил и российских агентов 25-27 июля в Тинзауатене, на севере Мали, недалеко от границы с Алжиром.Посол Украины в Сенегале также выразил безоговорочную поддержку малийским повстанцам, что привело к вызову посла в МИД Сенегала.',\n",
    "            'Еще новости афганской промышленности. В Кандагаре спустя 18 лет возобновила работу текстильная фабрика. Официальные лица говорят, что они отремонтировали оборудование на фабрике за шесть месяцев, сообщают афганское СМИ. По словам работников фабрики, с возобновлением работы фабрики созданы рабочие места. 69-летний Мохаммад, проработавший на текстильной фабрике в Кандагаре значительное время, рад вернуться на работу.',\n",
    "           'Накопленное непонимание между Китаем и США не может быть решено лишь одним подобным изящным жестом. Страны расходятся по широкому кругу вопросов, санкционный механизм против Китая не ослаблен. Поэтому отправка панд – это скорее демонстрация миролюбивой позиции Китая в противовес США.',\n",
    "            'В Алжире, как правило, на похоронах мужчины сидят около дома, хорошо, если есть сад или терраса, а женщины в доме, надеть платок женщина должна обязательно, даже если в обычной жизни она не покрывает голову. Если покойный жил в квартире, то прямо во дворе ставят стулья и шатры со столами для мужчин.Готовят либо нанятые кухарки, либо родственницы покойного. Пока составляла пост от подруги услышала,что в их семье часто еду приносят те, кто приходит в дом, а готовить должны невестки, а не дочери умершего. Мой муж сказал, что это совершенно необязательно, на похоронах его бабушки готовили только её дочери, это было их желание и никаких особых правил на счёт этого нет. Обязательного блюда на поминки в Алжире нет. Народ приходит помянутьот трех дней до недели, если у человека была большая семья и много знакомых!Кормят традиционными блюдами: суп-шорба, кус-кус/беркукес/тлитли с мясом и т.д.Могилу посещают каждое утро, в течении трех дней. Через 40 дней устанавливают небольшое надгробие, никаких памятников,вычурных элементов. На надгробии имя, фамилия, даты рождения и смерти, фотографий нет. Вроде бы написала всё, что знала. Задавайте вопросы в комментариях, если таковые имеются.',\n",
    "            'Сегодня в Венесуэле проходят президентские выборы. Мой коллега Дмитрий Морозов рассуждает, как их итоги могут повлиять на дальнейший путь страны. Вот самое важное из его статьи.📍В выборах один тур, участвуют десять кандидатов, однако только двое имеют реальные шансы на победу: действующий президент Николас Мадуро и Эдмундо Гонсалес Уррутия, кандидат от Единой демократической платформы, объединяющей наиболее значимые оппозиционные партии.'\n",
    "           ]\n",
    "x_temp = []\n",
    "for post_temp in new_text:\n",
    "        content = str(post_temp).lower()  \n",
    "        content = remove_emojis(content)\n",
    "        content = remove_chars_from_text(content, spec_chars)\n",
    "        content = remove_chars_from_text(content, string.digits)\n",
    "        for i in range(1, 10):\n",
    "            content = content.replace('  ', ' ')\n",
    "        x_temp.append(content)\n",
    "   \n",
    "\n",
    "count = CountVectorizer(vocabulary = set(X_train_words))\n",
    "X_t = count.transform(x_temp)\n",
    "accuracy = log_clf.predict(X_t)\n",
    "print (accuracy)\n",
    "print ('Predicted Probabilities: {} - {}'.format(log_clf.predict(X_t), log_clf.predict_proba(X_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d1cec50-5d5e-4bbe-ac40-c3557cc8f778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/ML/\n",
      "Africa\n",
      "China\n",
      "MiddleEAST\n",
      "LatAmerica\n",
      "IranPakistanAfganistan\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_ROOT = \"D:/ML/\"\n",
    "print(DOWNLOAD_ROOT)\n",
    "DATASET_PATH_test = os.path.join(\"datasets\", \"spam\")\n",
    "DIR_PATH_test = {\"Africa\":os.path.join(DATASET_PATH_test, \"Africa\"),\n",
    "            \"China\":os.path.join(DATASET_PATH_test, \"China\"),\n",
    "            \"MiddleEAST\":os.path.join(DATASET_PATH_test, \"MiddleEAST\"),\n",
    "           \"LatAmerica\":os.path.join(DATASET_PATH_test, \"LatAmerica\"),\n",
    "           \"IranPakistanAfganistan\":os.path.join(DATASET_PATH_test, \"IranPakistanAfganistan\"),}\n",
    "filenames = {}\n",
    "for items in DIR_PATH_test.keys():\n",
    "    print(items)\n",
    "    filenames[items] = [name for name in sorted(os.listdir(DIR_PATH_test[items])) if len(name) > 20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7212eea-4f5e-4508-93d6-8d06bee10013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from charset_normalizer import from_path\n",
    "import string\n",
    "\n",
    "def remove_chars_from_text(text, chars):\n",
    "    # return \"\".join([ch for ch in text if ch not in chars])\n",
    "    content = ''\n",
    "    for ch in text:\n",
    "        if ch not in chars:\n",
    "            content = content + ''.join(ch)\n",
    "        else:\n",
    "            content = content + ''.join(' ')\n",
    "    return content\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "spec_chars = string.punctuation + '\\r' + '\\n\\xa0«»\\t—…' \n",
    "\n",
    "x_test = []\n",
    "for item in filenames.keys():\n",
    "    post_temp=[]\n",
    "    for names in filenames[item]:\n",
    "        content = str(from_path(DIR_PATH_test[item]+\"\\\\\"+names).best()).lower()  \n",
    "        content = remove_emojis(content)\n",
    "        # content = re.sub(r'(\\\\u[0-9A-Fa-f]+)', lambda matchobj: chr(int(matchobj.group(0)[2:], 16)), content)\n",
    "        content = remove_chars_from_text(content, spec_chars)\n",
    "        content = remove_chars_from_text(content, string.digits)\n",
    "        for i in range(1, 10):\n",
    "            content = content.replace('  ', ' ')\n",
    "        x_test.append(content)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f088dbd2-f5e7-4d16-a916-1a7f4312c596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6906"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74743224-3890-4664-a491-e72409048e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afganistan' 'Afganistan' 'Afganistan' 'China' 'Afganistan' 'Afganistan'\n",
      " 'Afganistan' 'China' 'Afganistan' 'Afganistan' 'Afganistan' 'Afganistan'\n",
      " 'Afganistan' 'Afganistan' 'Afganistan' 'Afganistan' 'Afganistan'\n",
      " 'Afganistan' 'Afganistan' 'Afganistan' 'Afganistan' 'Afganistan'\n",
      " 'Afganistan' 'Afganistan' 'Afganistan' 'Afganistan' 'Afganistan'\n",
      " 'Afganistan' 'Afganistan' 'Afganistan' 'China' 'China' 'Afganistan'\n",
      " 'Afganistan' 'Afganistan' 'Afganistan' 'Afganistan' 'Afganistan'\n",
      " 'Afganistan' 'Afganistan' 'Afganistan' 'Afganistan' 'Afganistan'\n",
      " 'Afganistan' 'Afganistan' 'Iran' 'Afganistan' 'Afganistan' 'Afganistan'\n",
      " 'Afganistan']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predict</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>проведение новой международной встречи спецпре...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.971464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flydubai возобновила полеты в афганистан после...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.973447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>руководство афганистана не в полной мере контр...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.996161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>разведчик й роты го ооспн гру кандагар младший...</td>\n",
       "      <td>China</td>\n",
       "      <td>0.381928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сегодня в москве проходит международная конфер...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.973647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>сегодня в москве проходит международная конфер...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.973647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>афганскому народу нужно политическое решениек...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.781917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>на украине сша наступят на вьетнамские афганск...</td>\n",
       "      <td>China</td>\n",
       "      <td>0.561345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>никто в талибане не готов к компромиссу а нек...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.974867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>находящиеся в пакистане иностранные иммигранты...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.994815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>запад хочет сделать украину для россии вторым ...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.684881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>сша самый главный нарушитель прав человека в а...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.930344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>афганистан больше не лидер по производству опи...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.935723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>афганистан удвоил закупки спг из россииафганис...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.752765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>талибы не обеспечили безопасность соседних стр...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.998827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>представители национальных общин нескольких ре...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.966866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>дорогие подписчики друзья спешу поздравить вас...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.305054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>россия доставила в четверг в кабул очередную п...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.994606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>россия доставила в четверг в кабул очередную п...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.994606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>украину ждет судьба афганистана ирака ливии и ...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.782148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>в афганистане уже есть инклюзивное и ответстве...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.990863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>интересно конечно как некоторые каналы выдают ...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.591763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>выжившие после авиакатастрофы в афганистане ро...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.941663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>имеющие влияние на фнса силы тоже должны поощр...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.966574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>талибы выступили за укрепление регионального э...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.999707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>россия на предстоящей встрече в дохе по афгани...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.981022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>организация договора о коллективной безопаснос...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.913111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>в москве сочли провальной вторую конференцию п...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.884870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>глава комитета палаты представителей по иностр...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.994563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>численность боевиков исламского государства на...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.789812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>знакомьтесь с дашей российским журналистом афр...</td>\n",
       "      <td>China</td>\n",
       "      <td>0.661739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>знакомьтесь с дашей российским журналистом афр...</td>\n",
       "      <td>China</td>\n",
       "      <td>0.661739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>главной ошибкой соединенных штатов было то что...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.997547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>отец погибшего в афганистане американского вое...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.388629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>организация договора о коллективной безопаснос...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.795087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>интересно афганские нелегалы в великобритании ...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.751876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>я раньше много писала про женский бизнес в афг...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.952493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>госдепартамент сша слишком поздно принял решен...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.928605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>спецслужбы казахстана пресекли канал незаконно...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.958545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>талибы осудили теракт в крокус сити холле мид ...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.991415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>теракты свидетествуют о слабости врагов россии...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.973888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>фаузия куфи бывший вице спикер афганского парл...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.437764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>спецпредставитель президента ирана по афганист...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.748405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>в последние годы игил осуществляет вылазки про...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.939179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>министерство промышленности и торговли талибов...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.960137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>если бы не сотрудничество ирана и россии в сир...</td>\n",
       "      <td>Iran</td>\n",
       "      <td>0.624705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>борьба с террористическими группировками в афг...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.993098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>сейчас центры игил находятся за пределами афга...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.997358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>дорогие подписчики нам срочно надо поговорить ...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.627948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>иг не располагает возможностями для вербовки н...</td>\n",
       "      <td>Afganistan</td>\n",
       "      <td>0.831991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     predict  accuracy\n",
       "0   проведение новой международной встречи спецпре...  Afganistan  0.971464\n",
       "1   flydubai возобновила полеты в афганистан после...  Afganistan  0.973447\n",
       "2   руководство афганистана не в полной мере контр...  Afganistan  0.996161\n",
       "3   разведчик й роты го ооспн гру кандагар младший...       China  0.381928\n",
       "4   сегодня в москве проходит международная конфер...  Afganistan  0.973647\n",
       "5   сегодня в москве проходит международная конфер...  Afganistan  0.973647\n",
       "6    афганскому народу нужно политическое решениек...  Afganistan  0.781917\n",
       "7   на украине сша наступят на вьетнамские афганск...       China  0.561345\n",
       "8    никто в талибане не готов к компромиссу а нек...  Afganistan  0.974867\n",
       "9   находящиеся в пакистане иностранные иммигранты...  Afganistan  0.994815\n",
       "10  запад хочет сделать украину для россии вторым ...  Afganistan  0.684881\n",
       "11  сша самый главный нарушитель прав человека в а...  Afganistan  0.930344\n",
       "12  афганистан больше не лидер по производству опи...  Afganistan  0.935723\n",
       "13  афганистан удвоил закупки спг из россииафганис...  Afganistan  0.752765\n",
       "14  талибы не обеспечили безопасность соседних стр...  Afganistan  0.998827\n",
       "15  представители национальных общин нескольких ре...  Afganistan  0.966866\n",
       "16  дорогие подписчики друзья спешу поздравить вас...  Afganistan  0.305054\n",
       "17  россия доставила в четверг в кабул очередную п...  Afganistan  0.994606\n",
       "18  россия доставила в четверг в кабул очередную п...  Afganistan  0.994606\n",
       "19  украину ждет судьба афганистана ирака ливии и ...  Afganistan  0.782148\n",
       "20  в афганистане уже есть инклюзивное и ответстве...  Afganistan  0.990863\n",
       "21  интересно конечно как некоторые каналы выдают ...  Afganistan  0.591763\n",
       "22  выжившие после авиакатастрофы в афганистане ро...  Afganistan  0.941663\n",
       "23  имеющие влияние на фнса силы тоже должны поощр...  Afganistan  0.966574\n",
       "24  талибы выступили за укрепление регионального э...  Afganistan  0.999707\n",
       "25  россия на предстоящей встрече в дохе по афгани...  Afganistan  0.981022\n",
       "26  организация договора о коллективной безопаснос...  Afganistan  0.913111\n",
       "27  в москве сочли провальной вторую конференцию п...  Afganistan  0.884870\n",
       "28  глава комитета палаты представителей по иностр...  Afganistan  0.994563\n",
       "29  численность боевиков исламского государства на...  Afganistan  0.789812\n",
       "30  знакомьтесь с дашей российским журналистом афр...       China  0.661739\n",
       "31  знакомьтесь с дашей российским журналистом афр...       China  0.661739\n",
       "32  главной ошибкой соединенных штатов было то что...  Afganistan  0.997547\n",
       "33  отец погибшего в афганистане американского вое...  Afganistan  0.388629\n",
       "34  организация договора о коллективной безопаснос...  Afganistan  0.795087\n",
       "35  интересно афганские нелегалы в великобритании ...  Afganistan  0.751876\n",
       "36  я раньше много писала про женский бизнес в афг...  Afganistan  0.952493\n",
       "37  госдепартамент сша слишком поздно принял решен...  Afganistan  0.928605\n",
       "38  спецслужбы казахстана пресекли канал незаконно...  Afganistan  0.958545\n",
       "39  талибы осудили теракт в крокус сити холле мид ...  Afganistan  0.991415\n",
       "40  теракты свидетествуют о слабости врагов россии...  Afganistan  0.973888\n",
       "41  фаузия куфи бывший вице спикер афганского парл...  Afganistan  0.437764\n",
       "42  спецпредставитель президента ирана по афганист...  Afganistan  0.748405\n",
       "43  в последние годы игил осуществляет вылазки про...  Afganistan  0.939179\n",
       "44  министерство промышленности и торговли талибов...  Afganistan  0.960137\n",
       "45  если бы не сотрудничество ирана и россии в сир...        Iran  0.624705\n",
       "46  борьба с террористическими группировками в афг...  Afganistan  0.993098\n",
       "47  сейчас центры игил находятся за пределами афга...  Afganistan  0.997358\n",
       "48  дорогие подписчики нам срочно надо поговорить ...  Afganistan  0.627948\n",
       "49  иг не располагает возможностями для вербовки н...  Afganistan  0.831991"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_temp = []\n",
    "for post_temp in x_test[-150:-100]:\n",
    "        content = str(post_temp).lower()  \n",
    "        content = remove_emojis(content)\n",
    "        content = remove_chars_from_text(content, spec_chars)\n",
    "        content = remove_chars_from_text(content, string.digits)\n",
    "        for i in range(1, 10):\n",
    "            content = content.replace('  ', ' ')\n",
    "        x_temp.append(content)\n",
    "count = CountVectorizer(vocabulary = set(X_train_words))\n",
    "X_t = count.transform(x_temp)\n",
    "accuracy = log_clf.predict(X_t)\n",
    "\n",
    "print (accuracy)\n",
    "df = pd.DataFrame(log_clf.predict_proba(X_t), columns=log_clf.classes_)\n",
    "df_max = pd.DataFrame({'text': x_temp,'predict': log_clf.predict(X_t), 'accuracy': df.max(axis=1)})\n",
    "df_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5500ec13-8970-4d07-8478-007d078b8f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
